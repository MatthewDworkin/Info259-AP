{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2-regularized logistic regression for binary or multiclass classification; trains a model (on `train.txt`), optimizes L2 regularization strength on `dev.txt`, and evaluates performance on `test.txt`.  Reports test accuracy with 95% confidence intervals and prints out the strongest coefficients for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQTT9x-6d2JI"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import operator\n",
    "import nltk\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4KuVSCSqlUX",
    "outputId": "f4cf377b-6d74-473c-a945-828fa09bae92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols = line.split(\"\\t\")\n",
    "            idd = cols[0]\n",
    "            label = cols[2].lstrip().rstrip()\n",
    "            text = cols[3]\n",
    "\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGiM8qQiJOBU"
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "\n",
    "    def __init__(self, feature_method, feature_kwargs, trainX, trainY, devX, devY, testX, testY):\n",
    "        self.feature_vocab = {}\n",
    "        self.feature_method = feature_method\n",
    "        self.feature_kwargs = feature_kwargs\n",
    "        self.min_feature_count=2\n",
    "        self.log_reg = None\n",
    "\n",
    "        self.trainY=trainY\n",
    "        self.devY=devY\n",
    "        self.testY=testY\n",
    "        \n",
    "        self.trainX = self.process(trainX, training=True)\n",
    "        self.devX = self.process(devX, training=False)\n",
    "        self.testX = self.process(testX, training=False)\n",
    "\n",
    "    # Featurize entire dataset\n",
    "    def featurize(self, data):\n",
    "        featurized_data = []\n",
    "        for text in data:\n",
    "            feats = self.feature_method(text, **self.feature_kwargs)\n",
    "            featurized_data.append(feats)\n",
    "        return featurized_data\n",
    "\n",
    "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
    "    def process(self, X_data, training = False):\n",
    "        \n",
    "        data = self.featurize(X_data)\n",
    "\n",
    "        if training:\n",
    "            fid = 0\n",
    "            feature_doc_count = Counter()\n",
    "            for feats in data:\n",
    "                for feat in feats:\n",
    "                    feature_doc_count[feat]+= 1\n",
    "\n",
    "            for feat in feature_doc_count:\n",
    "                if feature_doc_count[feat] >= self.min_feature_count:\n",
    "                    self.feature_vocab[feat] = fid\n",
    "                    fid += 1\n",
    "\n",
    "        F = len(self.feature_vocab)\n",
    "        D = len(data)\n",
    "        X = sparse.dok_matrix((D, F))\n",
    "        for idx, feats in enumerate(data):\n",
    "            for feat in feats:\n",
    "                if feat in self.feature_vocab:\n",
    "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    # Train model and evaluate on held-out data\n",
    "    def train(self):\n",
    "        scaler = StandardScaler(with_mean=False)  # Use with_mean=False for sparse matrix compatibility\n",
    "        self.trainX = scaler.fit_transform(self.trainX)\n",
    "        self.devX = scaler.transform(self.devX)\n",
    "        self.testX = scaler.transform(self.testX)\n",
    "        (D,F) = self.trainX.shape\n",
    "        best_dev_accuracy=0\n",
    "        best_model=None\n",
    "        for C in [0.1, 1, 10, 100]:\n",
    "            self.log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
    "            self.log_reg.fit(self.trainX, self.trainY)\n",
    "            training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n",
    "            development_accuracy = self.log_reg.score(self.devX, self.devY)\n",
    "            if development_accuracy > best_dev_accuracy:\n",
    "                best_dev_accuracy=development_accuracy\n",
    "                best_model=self.log_reg\n",
    "\n",
    "#             print(\"C: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (C, training_accuracy, development_accuracy))\n",
    "\n",
    "        self.log_reg=best_model\n",
    "        \n",
    "\n",
    "    def test(self):\n",
    "        return self.log_reg.score(self.testX, self.testY)\n",
    "        \n",
    "\n",
    "    def printWeights(self, n=10):\n",
    "\n",
    "        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n",
    "        for k in self.feature_vocab:\n",
    "            reverse_vocab[self.feature_vocab[k]]=k\n",
    "\n",
    "        # binary\n",
    "        if len(self.log_reg.classes_) == 2:\n",
    "              weights=self.log_reg.coef_[0]\n",
    "\n",
    "              cat=self.log_reg.classes_[1]\n",
    "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "              cat=self.log_reg.classes_[0]\n",
    "              for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "        # multiclass\n",
    "        else:\n",
    "          for i, cat in enumerate(self.log_reg.classes_):\n",
    "\n",
    "              weights=self.log_reg.coef_[i]\n",
    "\n",
    "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load resources\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # For NER\n",
    "word_vectors = api.load(\"word2vec-google-news-300\")  # For Word Embeddings\n",
    "analyzer = SentimentIntensityAnalyzer()  # For Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def featurize(text, **kwargs):\n",
    "    feats = {}\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "#     # Basic BOW features\n",
    "    if kwargs.get('bag_of_words', True):\n",
    "        for word in words:\n",
    "            feats[f\"word_{word}\"] = 1\n",
    "\n",
    "    # Sentiment features\n",
    "    if kwargs.get('sentiment', False):\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        feats.update({\n",
    "            'sentiment_neg': sentiment['neg'],\n",
    "            'sentiment_neu': sentiment['neu'],\n",
    "            'sentiment_pos': sentiment['pos'],\n",
    "            'sentiment_compound': sentiment['compound']\n",
    "        })\n",
    "\n",
    "    # Word embeddings (averaged)\n",
    "    if kwargs.get('word_embed', False):\n",
    "        embeddings = [word_vectors[word] for word in words if word in word_vectors]\n",
    "        if embeddings:\n",
    "            avg_embedding = np.mean(embeddings, axis=0)\n",
    "            for i, value in enumerate(avg_embedding):\n",
    "                feats[f\"embedding_{i}\"] = value\n",
    "\n",
    "    # NER features\n",
    "    if kwargs.get('ner', False):\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            feats[f\"ner_{ent.label_}_{ent.text}\"] = 1\n",
    "            \n",
    "    if kwargs.get('hyperbolae', False):\n",
    "        hyperbolic_count = count_hyperbolic_terms(text)\n",
    "        feats['hyperbolic_count'] = hyperbolic_count\n",
    "        \n",
    "    if kwargs.get('topics', False):\n",
    "        topics = get_document_topics(text)\n",
    "        for topic_id, weight in topics:\n",
    "            if weight > 0.5:\n",
    "                feats[f\"topic_{topic_id}\"] = weight\n",
    "            \n",
    "    return feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_intervals(accuracy, n, significance_level):\n",
    "    critical_value=(1-significance_level)/2\n",
    "    z_alpha=-1*norm.ppf(critical_value)\n",
    "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
    "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(trainingFile, devFile, testFile, featurize_kwargs={}):\n",
    "    trainX, trainY=load_data(trainingFile)\n",
    "    devX, devY=load_data(devFile)\n",
    "    testX, testY=load_data(testFile)\n",
    "    \n",
    "    simple_classifier = Classifier(featurize, featurize_kwargs, trainX, trainY, devX, devY, testX, testY)\n",
    "    simple_classifier.train()\n",
    "    accuracy=simple_classifier.test()\n",
    "    \n",
    "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
    "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
    "\n",
    "    simple_classifier.printWeights()\n",
    "    return accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adj_data = pd.read_table(\"./AP2/adjudicated_data.txt\")\n",
    "adj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(adj_data, test_size=100)\n",
    "train, dev = train_test_split(train, test_size=100)\n",
    "len(train), len(dev), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"./splits/train.txt\", sep=\"\\t\", index=False)\n",
    "dev.to_csv(\"./splits/dev.txt\", sep=\"\\t\", index=False)\n",
    "test.to_csv(\"./splits/test.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainingFile = \"splits/train.txt\"\n",
    "devFile = \"splits/dev.txt\"\n",
    "testFile = \"splits/test.txt\"\n",
    "\n",
    "featurize_kwargs = {\n",
    "    'bag_of_words': True\n",
    "}\n",
    "    \n",
    "run(trainingFile, devFile, testFile, featurize_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving on the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def sentiment_scores(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load pre-trained Word2Vec model.\n",
    "word_vectors = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def get_word_embedding(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    embeddings = [word_vectors[word] for word in words if word in word_vectors]\n",
    "    # Average the word vectors of all words in the text\n",
    "    if embeddings:\n",
    "        return sum(embeddings) / len(embeddings)\n",
    "    else:\n",
    "        return np.zeros(300)  # Return zero vector if no words have embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load an English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "trainingFile = \"splits/train.txt\"\n",
    "devFile = \"splits/dev.txt\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase, remove special characters, and tokenize text\n",
    "    tokens = word_tokenize(re.sub(r'[\\W_]+', ' ', text.lower()))\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
    "    return tokens\n",
    "\n",
    "def read_documents(file_path):\n",
    "    documents = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            cells = line.split(\"\\t\")\n",
    "            documents.append(preprocess_text(cells[-1]))\n",
    "            \n",
    "    return documents\n",
    "\n",
    "# Read and preprocess the training and dev data\n",
    "train_documents = read_documents(trainingFile)\n",
    "dev_documents = read_documents(devFile)\n",
    "\n",
    "# Combine train and dev documents if you want to use both for training\n",
    "documents = train_documents + dev_documents\n",
    "\n",
    "# Assuming 'documents' is a list of tokenized documents (list of list of tokens)\n",
    "dictionary = Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, random_state=42)\n",
    "\n",
    "\n",
    "def get_document_topics(text):\n",
    "    tokens = preprocess_text(text)\n",
    "    # Get the bag-of-words representation for the text\n",
    "    bow = dictionary.doc2bow(tokens)\n",
    "    # Retrieve the list of topics with their probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "\n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperbolic Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperbolic_terms = [\"unbelievable\", \"amazing\", \"incredible\", \"never\", \"always\", \"worst\", \"best\"]\n",
    "\n",
    "def count_hyperbolic_terms(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    count = sum(1 for word in words if word in hyperbolic_terms)\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "params = {\n",
    "    'bag_of_words': [True, False],\n",
    "    'sentiment': [True, False],\n",
    "    'word_embed': [True, False],\n",
    "    'ner': [True, False],\n",
    "    'hyperbolae': [True, False],\n",
    "    'topics': [True, False]\n",
    "}\n",
    "\n",
    "keys = params.keys()\n",
    "values = (params[key] for key in keys)\n",
    "kwargs_combinations = [dict(zip(keys, combination)) \n",
    "                for combination in product(*values) \n",
    "                if any(combination)]\n",
    "# featurize_kwargs = {\n",
    "#     'bag_of_words': False,\n",
    "#     'sentiment': False,\n",
    "#     'word_embed': True,\n",
    "#     'ner': True, \n",
    "#     'hyperbolae': False,\n",
    "#     'topics': True\n",
    "# }\n",
    "    \n",
    "# run(trainingFile, devFile, testFile, featurize_kwargs)\n",
    "\n",
    "results = []\n",
    "\n",
    "for kwarg_combination in tqdm(kwargs_combinations):\n",
    "    # Run the model with the current combination of features\n",
    "    accuracy = run(trainingFile, devFile, testFile,kwarg_combination)\n",
    "    results.append((kwarg_combination, accuracy))\n",
    "\n",
    "# Find the best performing configuration\n",
    "best_combination = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(\"Best configuration:\", best_combination[0])\n",
    "print(\"Highest accuracy:\", best_combination[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
